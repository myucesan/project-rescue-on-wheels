\documentclass[12pt]{article}
\usepackage[T1]{fontenc}
\usepackage{listings}
\usepackage{tikz}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{array}
\usepackage{titlesec}
\usepackage[a4paper, margin=1in]{geometry}
\usepackage[hidelinks]{hyperref}
\usepackage{placeins}
\usepackage{float}
\usepackage{color}
\usepackage{rotating}
\usepackage{hyperref}
\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}
\hypersetup{
	colorlinks,
	citecolor=black,
	filecolor=black,
	linkcolor=black,
	urlcolor=black
}
\setcounter{tocdepth}{4}
\setcounter{secnumdepth}{4}
\begin{document}
	\title{\huge Rescue on wheels project documentation}
	\author{\\Team 2\\ \\Damian de Hoog 500780277\\ Yoshio Schermer 500760587\\Mustafa Y\"{u}cesan 500769574\\ Mohamed El Hadiyen 500777214}
	\maketitle
	\newpage
	\tableofcontents
	\newpage
	\section{Introduction}
	This document contains all the information regarding "Metabot" our rescue on wheels project. This document will describe the design phase, working phase and post-launch phase consisting of:
	\begin{itemize}
		\item An analysis of the requirements for the project from the perspective of an user.
		\item A design model which explains in great detail how the system is built.
		\item Documentation containing important code segments with comments and explanations as well guidance for installation, operation and maintenance.
	\end{itemize} 
	Metabot is a Raspberry Pi powered mobile robot designed to assist in rescue operations. The robot will be able to navigate difficult to traverse environments and explore areas as a sort of reconnaissance unit.\\
	Metabot is equipped with a camera which will broadcast to a mobile device on which the user can control the robot as well as see said camera feed. The camera has a facial recognition functionality to assist in spotting survivors.\\
	Whilst navigating the operating environment Metabot will map the area and ping locations on the map when survivors are found.\\ 
	\\Metabot will be able to explore and create a map of the area with the locations of survivors. This way, having seen the environment and knowing the locations of the survivors,  the rescue team will be able to conduct a swift and efficient rescue operation.\\
	\\The following chapters will describe the robot in more details as well as it's design. We will begin with the analysis of the requirements for the Metabot. 
	\newpage
	\section{Analysis}
	The analysis consists of the following parts:
	\begin{itemize}
		\item Epic
		\item User stories
		\item Use-cases
		\item Use-case diagram
		\item Domain model\\
	\end{itemize}	
	The analysis answers the question of "How, in detail, is the product designed?"\\
	\\The formulation of the requirements was performed based on user stories. These user stories were created based on an epic. An agile epic is a body of work that can be broken down into specific tasks (called ''stories,'' or ''user stories'') based on the needs/requests of customers or end users\footnote{https://www.atlassian.com/agile/project-management/epics}.\\
	\\After having created said requirements we will formulate the Use-case diagram(s) and the Domain model(s). These will visualize the user interaction with our system and our Metabot.
	\subsubsection{Terms and definitions}
	Below you'll find the terms and definitions used throughout this document.
	\begin{table}[H]
		\centering
		\begin{tabularx}{\linewidth}{|X|X|}
			\hline
			\textbf{Terms} &\textbf{Definitions}\\
			\hline
			Rover &Remotely-controllable RC-car with sensors attached to it.\\
			\hline
			App &The mobile app through which the rover can be remotely-controlled.\\
			\hline
			Rover operator &An individual who operates the rover.\\
			\hline
			Web interface &The web interface through which the rover can be remotely-controlled. \\
			\hline 
			Livestream &A livestream of the camera feed that is attached to the rover.\\
			\hline
		\end{tabularx}
		\caption{Terms and definitions for this document.}
		\label{table:termsDefinition}   
	\end{table}
	\newpage
	\subsection{Epic}
	 A building has collapsed trapping the people inside. Some managed to get out in time but others weren't so lucky. Upon arrival at the scene our actor assesses the situation. The building is unstable and the trapped survivors need to be rescued as quickly as possible.\\
	 \\Normally a rescue crew would be assembled and they would slowly make their way through the rubble to search for people. This is a dangerous and time-consuming task. The crew has no idea whether or not there is a way to get to the survivors. Removing rubble could make the building collapse even further. These people need to be found and removed from the ruins before this happens.\\
	 \\Luckily our actor has just the tool for this job. The Metabot, a small remote controlled robot that can do the scouting for our actor. Our actor takes out his phone and boots up the app. Here, our actor can control the robot.\\
	 \\Our actor sends the robot into the ruins, slowly making it's way deeper and deeper into the building. Whilst moving, the robot sends out signals to its surroundings to map the area and to avoid collision with objects. Meanwhile, our actor can see what the robot is seeing through the live camera feed. Our actor uses this feed to try and find survivors while also looking around for possible routes to take with the rescue crew.\\
	 \\Once our actor has found a survivor, the robot's facial recognition software will help our actor detect the survivor. After this detection, the robot will ping the location of the survivor on the map so that our actor knows where in relation to the rest of the building the survivors are. After pinging the location, the robot will give a visual light signal to the survivors to let them know they have been found and will soon be rescued.\\
	 \\After mapping the area and locating the survivors our actor can create a rescue plan and execute it. Having performed reconnaissance safely and quickly with the Metabot, our rescue crew can now swiftly save the survivors. 
	 \newpage
	\subsection{User stories}
	 From this epic story we could formulate user stories, this resulted in the following table:
	 \begin{table}[H]
	 	\centering
	 	\begin{tabularx}{\linewidth}{|X|X|X|X|}
	 		\hline
	 		\textbf{M: As operator I want to be able to recognize a survivor's face, so I can get information about this survivor.}                                               &\textbf{M: As operator I want to visually explore the environment from a distance, so I can be better prepared for the rescue operation.}       &\textbf{S: As operator I want to know the locations of the survivors in relation to the environment, so that I know where I can find the survivors.}
	 		                                                        &\textbf{S: As a survivor I want to know if I have been found, so I can be rescued.}
	 		                                                                                    \tabularnewline \hline
	 		As operator I want a mobile robot to recognize a survivor's face, so I can get information about this survivor                                              &As operator I want the mobile robot to show me the environment on a screen at a distance so that I can plan the rescue operation accordingly.                                          &As operator I want a mobile robot to tell a mobile app where the survivor is in relation to the environment, so that I know where I can find the survivors.                                            &As survivor I want the mobile robot to give me a sign, so I know I have been found.
	 		\tabularnewline \hline
	 		As operator I want a mobile app to get the information that corresponds to the survivor's face, so I know who the survivor is.                                                   &As operator I want the mobile robot to stream the camera feed to a mobile device so I can get real time information from the environment.   &As operator I want a mobile app to display where the survivors are in relation to the environment, so that I know where I can find the survivors. &   \tabularnewline \hline
	 	                                               &As operator I want to control the mobile robot from a distance to plan the rescue operation accordingly.  & &
            \tabularnewline \hline
	 	\end{tabularx}
	 	\caption{User stories formed in accordance with the epic story.}
	 	\label{table:userStories}   
	 \end{table}
 	
 	\subsection{Use-cases}
	 	\begin{table}[H]
	 	\centering
		 	\begin{tabularx}{\linewidth}{|X|X|}
		 		\hline
		 		\textbf{Use Case ID:} &1\\
		 		\hline
		 		\textbf{Use Case Name:} &Connect with rover\\
		 		\hline
		 		\textbf{Primary Actor:} &Rover operator\\
		 		\hline
		 		\textbf{Secondary Actor:} &Rover\\
		 		\hline
		 		\textbf{Pre-conditions:} &\begin{enumerate}
		 			\item Rover operator has mobile app or address of web interface.
		 			\item Rover is nearby.
		 		\end{enumerate}\\
		 		\hline
		 		\textbf{Success Guarantee:} &Rover operator successfully connected the mobile app/web interface to the rover. \\
		 		\hline 
		 		\textbf{Main Success Scenario:} &\begin{enumerate}
		 			\item Rover operator opens app or goes to the web interface.
		 			\item Rover operator searches for rover to connect to within the app.
		 			\item Rover operator selects rover to connect to.
		 			\item Rover operator confirms to connect to the selected rover.
		 			\item Rover operator successfully connected the app/web interface to the rover.
		 		\end{enumerate}\\
		 		\hline
		 		\textbf{Exceptions} &\begin{itemize}
		 			\item Rover operator already has established a connection between the app/web interface and the rover.
		 			\item Rover operator cannot connect app/web interface to the rover, because the rover is already connected with the same app/web interface from another rover operator.
		 			
		 		\end{itemize}\\
		 		\hline
		 		\textbf{Special Requirements} &- \\
		 		\hline
		 	\end{tabularx}
		 	\caption{Use-case 1}
		 	\label{table:Use-case1}   
	 	\end{table}
	 	\begin{table}[H]
	 		\centering
	 		\begin{tabularx}{\linewidth}{|X|X|}
	 			\hline
	 			\textbf{Use Case ID:} &2\\
	 			\hline
	 			\textbf{Use Case Name:} &Look for survivors on flat surfaces\\
	 			\hline
	 			\textbf{Primary Actor:} &Rover operator\\
	 			\hline
	 			\textbf{Secondary Actor:} &Rover\\
	 			\hline
	 			\textbf{Pre-conditions:} &\begin{enumerate}
	 				\item Rover operator has established a connection between the app /web interface and the rover.
	 				\item Rover operator sees what the rover sees.
	 				\item Rover operator has controller.
	 			\end{enumerate}\\
	 			\hline
	 			\textbf{Success Guarantee:} &
	 			Rover operator uses the rover to look for survivors on flat surfaces, that is, drives around. \\
	 			\hline 
	 			\textbf{Main Success Scenario:} &\begin{enumerate}
	 				\item Rover operator uses controller to drive either forward, backward, left, or right.
	 				\item Rover operator uses the live stream to look for any survivors.
	 			\end{enumerate}\\
	 			\hline
	 			\textbf{Exceptions} &-\\
	 			\hline
	 			\textbf{Special Requirements} &-\\
	 			\hline
	 		\end{tabularx}
	 		\caption{Use-case 2}
	 		\label{table:Use-case2}   
	 	\end{table}
	 	\begin{table}[H]
	 		\centering
	 		\begin{tabularx}{\linewidth}{|X|X|}
	 			\hline
	 			\textbf{Use Case ID:} &3\\
	 			\hline
	 			\textbf{Use Case Name:} &Know who a survivor is and where they are\\
	 			\hline
	 			\textbf{Primary Actor:} &Rover operator\\
	 			\hline
	 			\textbf{Secondary Actor:} &Rover\\
	 			\hline
	 			\textbf{Pre-conditions:} &\begin{enumerate}
	 				\item Rover operator has established a connection between the app/web interface and the rover.
	 				\item Rover operator sees what the rover sees.
	 				\item Rover operator has controller.
	 			\end{enumerate}\\
	 			\hline
	 			\textbf{Success Guarantee:} &Rover operator drives around with the rover. Through the livestream the rover operator can see who the survivor is and where they are to be seen. \\
	 			\hline 
	 			\textbf{Main Success Scenario:} &\begin{enumerate}
	 				\item Rover operator uses controller to drive either forward, backward, left, or right.
	 				\item Rover operator uses the live stream to look for any survivors.
	 				\item A survivorâ€™s face is visible through the livestream.
	 				\item Through the livestream the rover operator can tell who the survivor is and where the face of the survivor is.
	 			\end{enumerate}\\
	 			\hline
	 			\textbf{Exceptions} &-\\
	 			\hline
	 			\textbf{Special Requirements} &-\\
	 			\hline
	 		\end{tabularx}
	 		\caption{Use-case 3}
	 		\label{table:Use-case3}   
	 	\end{table}
	 	\begin{table}[H]
	 		\centering
	 		\begin{tabularx}{\linewidth}{|X|X|}
	 			\hline
	 			\textbf{Use Case ID:} &4\\
	 			\hline
	 			\textbf{Use Case Name:} &Tracking the location of the rover\\
	 			\hline
	 			\textbf{Primary Actor:} &Rover operator\\
	 			\hline
	 			\textbf{Secondary Actor:} &Rover\\
	 			\hline
	 			\textbf{Pre-conditions:} &\begin{enumerate}
	 				\item Rover operator has established a connection between the web interface and the rover.
	 				\item Rover operator has controller.
	 			\end{enumerate}\\
	 			\hline
	 			\textbf{Success Guarantee:} &
	 			Rover operator tracks the location of the rover through a map on the web interface \\
	 			\hline 
	 			\textbf{Main Success Scenario:} &\begin{enumerate}
	 				\item Rover operator uses controller to drive either forward, backward, left, or right.
	 				\item Rover operator sees location of the rover changing in the same direction as he/she is moving it.
	 			\end{enumerate}\\
	 			\hline
	 			\textbf{Exceptions} &-\\
	 			\hline
	 			\textbf{Special Requirements} &When the rover is unable to move in a certain direction because of an obstacle then this should be reflected in the map as not having moved. \\
	 			\hline
	 		\end{tabularx}
	 		\caption{Use-case 4}
	 		\label{table:Use-case4}   
	 	\end{table}
	 	\begin{table}[H]
	 		\centering
	 		\begin{tabularx}{\linewidth}{|X|X|}
	 			\hline
	 			\textbf{Use Case ID:} &5\\
	 			\hline
	 			\textbf{Use Case Name:} &Backtracking the rover\\
	 			\hline
	 			\textbf{Primary Actor:} &Rover operator\\
	 			\hline
	 			\textbf{Secondary Actor:} &Rover\\
	 			\hline
	 			\textbf{Pre-conditions:} &\begin{enumerate}
	 				\item Rover operator has established a connection between the web interface and the rover.
	 				\item Rover operator has controller.
	 			\end{enumerate}\\
	 			\hline
	 			\textbf{Success Guarantee:} &Rover returns to initial position in the opposite way as it has moved to its current position.\\
	 			\hline 
	 			\textbf{Main Success Scenario:} &\begin{enumerate}
	 				\item Rover operator uses controller to drive either forward, backward, left, or right.
	 				\item Rover operator turns backtracking on.
	 				\item Rover goes back to its initial position.
	 			\end{enumerate}\\
	 			\hline
	 			\textbf{Exceptions} &-\\
	 			\hline
	 			\textbf{Special Requirements} & Moments where the rover stopped are ignored. So, the rover drives back directly without stopping.\\
	 			\hline
	 		\end{tabularx}
	 		\caption{Use-case 5}
	 		\label{table:Use-case5}   
	 	\end{table}
 	\subsection{Use-case diagram}
 	\includegraphics[width=\linewidth]{UseCaseDiagram.jpeg}
 	\subsection{Domain model}
 	\includegraphics[width=\linewidth]{DomainModel.jpeg}
 	\newpage
 	\section{Testing}
 	In the fourth sprint we conducted multiple tests:
 	\subsection{General tests}
 	\begin{table}[H]
 		\centering
 		\begin{tabularx}{\linewidth}{|X|X|}
 			\hline
 			\textbf{ID} &1\\
 			\hline
 			\textbf{Testgoal} &Proof that it can be remote-controlled successfully via the camera\\
 			\hline
 			\textbf{Version} &1\\
 			\hline
 			\textbf{Testers} &Mustafa, Yoshio\\
 			\hline
 			\textbf{Date} &21 Dec 2018 at 2:30pm\\
 			\hline
 			\textbf{Location} &AUAS, WBH3\\
 			\hline
 			\textbf{Device(s)} &MacOS, Chrome\\
 			\hline
 			\textbf{Approach} &Operator cannot see rover. He/she can only see the web interface. 	Therefore, the camera on the rover must only be used to control.\\
 			\hline
 			\textbf{Proof} &Video demonstration\\
 			\hline
 			\textbf{Conclusion} &Test successful. Operator is able to control the rover using only the camera on the rover.\\
 			\hline
 		\end{tabularx}
 		\caption{Testcase 1}
 		\label{table:Testcase 1}   
 	\end{table}
	 \begin{table}[H]
	 	\centering
	 	\begin{tabularx}{\linewidth}{|X|X|}
	 		\hline
	 		\textbf{ID} &2\\
	 		\hline
	 		\textbf{Testgoal} &Proof that it can recognize faces\\
	 		\hline
	 		\textbf{Version} &1\\
	 		\hline
	 		\textbf{Testers} &Mustafa, Yoshio\\
	 		\hline
	 		\textbf{Date} &21 Dec 2018 at 1pm\\
	 		\hline
	 		\textbf{Location} &AUAS, WBH3\\
	 		\hline
	 		\textbf{Device(s)} &MacOS, Chrome\\
	 		\hline
	 		\textbf{Approach} &Mr Bean's face is trained and is the only face trained. We first show Mr Bean's face. His face should be recognized. Afterwards we show another person's face. That person's face should be unknown and most certainly not to be recognized as Mr Bean.\\
	 		\hline
	 		\textbf{Proof} &Video demonstration\\
	 		\hline
	 		\textbf{Conclusion} &The test was successful. Mr Bean's face was recognized at a percentage of 50\%. Our own was considered to be unknown. There is, however, a significant delay of ~1.5 seconds relative to real-time.\\
	 		\hline
	 	\end{tabularx}
	 	\caption{Testcase 2}
	 	\label{table:Testcase 2}   
	 \end{table}
 	\begin{table}[H]
 		\centering
 		\begin{tabularx}{\linewidth}{|X|X|}
 			\hline
 			\textbf{ID} &3\\
 			\hline
 			\textbf{Testgoal} &Proof that light turns on when it's dark\\
 			\hline
 			\textbf{Version} &1\\
 			\hline
 			\textbf{Testers} &Yoshio\\
 			\hline
 			\textbf{Date} &21 Dec 2018 at 3:30pm\\
 			\hline
 			\textbf{Location} &AUAS, WBH3\\
 			\hline
 			\textbf{Device(s)} &Windows 10, Chrome\\
 			\hline
 			\textbf{Approach} &Cover the rover with something like a blanket. The light should then turn on. Removing the blanket should result in the light turning off.\\
 			\hline
 			\textbf{Proof} &Video demonstration\\
 			\hline
 			\textbf{Conclusion} &Test successful. Covering causes the light to turn on, removing cover turns it off.\\
 			\hline
 		\end{tabularx}
 		\caption{Testcase 3}
 		\label{table:Testcase 3}   
 	\end{table}
 	\begin{table}[H]
 	\centering
	 	\begin{tabularx}{\linewidth}{|X|X|}
	 		\hline
	 		\textbf{ID} &4\\
	 		\hline
	 		\textbf{Testgoal} &Proof that light turns on when it's dark\\
	 		\hline
	 		\textbf{Version} &1\\
	 		\hline
	 		\textbf{Testers} &Mustafa, Yoshio\\
	 		\hline
	 		\textbf{Date} &21 Dec 2018 at 2pm\\
	 		\hline
	 		\textbf{Location} &AUAS, WBH3\\
	 		\hline
	 		\textbf{Device(s)} &MacOS, Chrome\\
	 		\hline
	 		\textbf{Approach} &Type text into text field on the web interface. Subsequently check if text can be seen on the display.\\
	 		\hline
	 		\textbf{Proof} &Video demonstration\\
	 		\hline
	 		\textbf{Conclusion} &Test was successful. We followed the instructions, no problems arose.\\
	 		\hline
	 	\end{tabularx}
 	\caption{Testcase 4}
 	\label{table:Testcase 4}   
	\end{table}
	\begin{table}[H]
		\centering
		\begin{tabularx}{\linewidth}{|X|X|}
			\hline
			\textbf{ID} &5\\
			\hline
			\textbf{Testgoal} &Proof that temperature works\\
			\hline
			\textbf{Version} &1\\
			\hline
			\textbf{Testers} &Mustafa, Yoshio\\
			\hline
			\textbf{Date} &21 Dec 2018 at 3pm\\
			\hline
			\textbf{Location} &AUAS, WBH3\\
			\hline
			\textbf{Device(s)} &MacOS, Chrome\\
			\hline
			\textbf{Approach} &Put finger on sensor. The web interface should display a higher temperature (finger temperature > room temperature). Also use a cold drink and push against the sensor, this should decrease the temperature.\\
			\hline
			\textbf{Proof} &Video demonstration\\
			\hline
			\textbf{Conclusion} &Test unsuccessful. Probably calculation mistake. The temperature decreases when temperature is higher and decreases when lower.\\
			\hline
		\end{tabularx}
		\caption{Testcase 5}
		\label{table:Testcase 5}   
	\end{table}
	\begin{table}[H]
		\centering
		\begin{tabularx}{\linewidth}{|X|X|}
			\hline
			\textbf{ID} &6\\
			\hline
			\textbf{Testgoal} &Proof that distance sensor works\\
			\hline
			\textbf{Version} &1\\
			\hline
			\textbf{Testers} &Mustafa, Yoshio\\
			\hline
			\textbf{Date} &21 Dec 2018 at 2pm\\
			\hline
			\textbf{Location} &AUAS, WBH3\\
			\hline
			\textbf{Device(s)} &MacOS, Chrome\\
			\hline
			\textbf{Approach} &Put hand in front of sensor and move forward/backwards. It should be able to accurately determine the distance of objects between itself when the distance is between 25cm and 55cm. It should also remain constant when the object doesn't move.\\
			\hline
			\textbf{Proof} &Video demonstration\\
			\hline
			\textbf{Conclusion} &Test successful. Moving hand closer than 25cm gives inaccurate measurements and the same goes for distances larger than 55cm. In between the distance is accurately measured and constant.\\
			\hline
		\end{tabularx}
		\caption{Testcase 6}
		\label{table:Testcase 6}   
	\end{table}
	\begin{table}[H]
		\centering
		\begin{tabularx}{\linewidth}{|X|X|}
			\hline
			\textbf{ID} &7\\
			\hline
			\textbf{Testgoal} &Proof that compass works\\
			\hline
			\textbf{Version} &1\\
			\hline
			\textbf{Testers} &Mustafa, Yoshio\\
			\hline
			\textbf{Date} &21 Dec 2018 at 2pm\\
			\hline
			\textbf{Location} &AUAS, WBH3\\
			\hline
			\textbf{Device(s)} &MacOS, Chrome\\
			\hline
			\textbf{Approach} &Turn rover 90 degrees. This should match a turn of a phone turning the same angle.\\
			\hline
			\textbf{Proof} &Video demonstration\\
			\hline
			\textbf{Conclusion} &Test unsuccessful. Probably a hardware/interference problem, because code seems to work for others.\\
			\hline
		\end{tabularx}
		\caption{Testcase 7}
		\label{table:Testcase 7}   
	\end{table}
	\begin{table}[H]
		\centering
		\begin{tabularx}{\linewidth}{|X|X|}
			\hline
			\textbf{ID} &8\\
			\hline
			\textbf{Testgoal} &Proof that backtracking works\\
			\hline
			\textbf{Version} &1\\
			\hline
			\textbf{Testers} &Mustafa, Yoshio\\
			\hline
			\textbf{Date} &21 Dec 2018 at 3pm\\
			\hline
			\textbf{Location} &AUAS, WBH3\\
			\hline
			\textbf{Device(s)} &MacOS, Chrome\\
			\hline
			\textbf{Approach} &Drive forward, then a 90 degree angle to either left/right. Drive forward. Then backtrack. It should return to its initial position.\\
			\hline
			\textbf{Proof} &Video demonstration\\
			\hline
			\textbf{Conclusion} &Test was unsuccessful due to one or more wheels not working fully. Also only driving forward and then backtracking, causes it to go more backwards then forwards. No attention has been given to the fact that the motors are running at full power until the last millisecond.\\
			\hline
		\end{tabularx}
		\caption{Testcase 8}
		\label{table:Testcase 8}   
	\end{table}
	\begin{table}[H]
		\centering
		\begin{tabularx}{\linewidth}{|X|X|}
			\hline
			\textbf{ID} &9\\
			\hline
			\textbf{Testgoal} &Proof that map corresponds to route taken\\
			\hline
			\textbf{Version} &1\\
			\hline
			\textbf{Testers} &Mustafa, Yoshio\\
			\hline
			\textbf{Date} &21 Dec 2018 at 3pm\\
			\hline
			\textbf{Location} &AUAS, WBH3\\
			\hline
			\textbf{Device(s)} &MacOS, Chrome\\
			\hline
			\textbf{Approach} &Drive forwards, then the operator should see that the line has moved forward. Drive an other direction then the operator should see that the line has moved into that direction.\\
			\hline
			\textbf{Proof} &Video demonstration\\
			\hline
			\textbf{Conclusion} &Line doesn't completely correspond to route taken due to the way the robot senses turns. The line is being generated though when it moves, but just not entirely accurate. Other approaches unfortunately weren't possible due to inconsistencies as well. Therefore, this is as of now the best we can do.\\
			\hline
		\end{tabularx}
		\caption{Testcase 9}
		\label{table:Testcase 9}   
	\end{table}
	\begin{table}[H]
		\centering
		\begin{tabularx}{\linewidth}{|X|X|}
			\hline
			\textbf{ID} &10\\
			\hline
			\textbf{Testgoal} &Proof that when backtracking the rover stops moving when an object is behind it (25-55cm)\\
			\hline
			\textbf{Version} &1\\
			\hline
			\textbf{Testers} &Yoshio\\
			\hline
			\textbf{Date} &21 Dec 2018 at 4pm\\
			\hline
			\textbf{Location} &AUAS, WBH3\\
			\hline
			\textbf{Device(s)} &Windows 10, Chrome\\
			\hline
			\textbf{Approach} &Drive forward, then place an object behind it 25-55cm. Then activate backtrack. It should stop almost immediately.\\
			\hline
			\textbf{Proof} &Video demonstration\\
			\hline
			\textbf{Conclusion} &Test successful. It does, however, tend to drive a little too much backwards.\\
			\hline
		\end{tabularx}
		\caption{Testcase 10}
		\label{table:Testcase 10}   
	\end{table}
	\begin{table}[H]
		\centering
		\begin{tabularx}{\linewidth}{|X|X|}
			\hline
			\textbf{ID} &11\\
			\hline
			\textbf{Testgoal} &Proof that when backtracking the rover moves the distance sensor via the servo so it can detect objects from different angles as well.\\
			\hline
			\textbf{Version} &1\\
			\hline
			\textbf{Testers} &Yoshio\\
			\hline
			\textbf{Date} &21 Dec 2018 at 3:45pm\\
			\hline
			\textbf{Location} &AUAS, WBH3\\
			\hline
			\textbf{Device(s)} &Windows 10, Chrome\\
			\hline
			\textbf{Approach} &Drive forward, then place an object behind it 25-55cm within a degree of 90. Then activate backtrack. It should stop almost immediately.\\
			\hline
			\textbf{Proof} &None\\
			\hline
			\textbf{Conclusion} &Test successful when little interference is present.\\
			\hline
		\end{tabularx}
		\caption{Testcase 11}
		\label{table:Testcase 11}   
	\end{table}
	\subsection{Acceptance tests}
	\begin{table}[H]
		\centering
		\begin{tabularx}{\linewidth}{|X|X|}
			\hline
			\textbf{ID} &1\\
			\hline
			\textbf{Name} &Connect with rover\\
			\hline
			\textbf{Basis} &\begin{itemize}
								\item Use case: connect with rover
								\item User story: connect app to rover
							\end{itemize}\\
			\hline
			\textbf{Figure(s)} &1, 2 \\
			\hline
			\textbf{Pre-conditions} & \begin{itemize}
									  	\item Rover nearby
									  	\item Mobile app opened
									  	\item Connected through Wifi with rover hotspot
									  \end{itemize}\\
			\hline
			\textbf{Test} &Given: List of rovers to connect to\\
						&When: Select rover from list\\
						&Then: Selected and visual cue that rover is selected\\
						&\\
						&Given: List of rovers to connect to while rover already selected\\
						&When: Select other rover from list\\
						&Then: Selected and visual cue that other rover is selected\\
						&\\
						&Given: List of rovers to connect to while rover already selected\\
						&When: Select same rover from list\\
						&Then: Selection and visual cue remain the same\\
						&\\
						&Given: Selected rover from list\\
						&When: Click on connect button\\
						&Then: See Rover UI with rover no. of selected rover\\
			\hline
			\textbf{Remarks} &When I try to go through the list, the item I put my finger upon is automatically selected as well, even when my intention wasn't to.\\
			\hline
		\end{tabularx}
		\caption{Acceptance test 1}
		\label{table:Acceptance test 1}   
	\end{table}
	\begin{table}[H]
		\centering
		\begin{tabularx}{\linewidth}{|X|X|}
			\hline
			\textbf{ID} &2\\
			\hline
			\textbf{Name} &See what rover sees\\
			\hline
			\textbf{Basis} &\begin{itemize}
				\item Use case: look for survivors on flat surfaces
				\item User story: see what rover sees
			\end{itemize}\\
			\hline
			\textbf{Figure(s)} &1, 2 \\
			\hline
			\textbf{Pre-conditions} & \begin{itemize}
				\item Connected with rover
			\end{itemize}\\
			\hline
			\textbf{Test} &Given: Rover UI of a rover\\
			&Then: See what camera of rover sees through UI\\
			&\\
			&Given: Rover UI of a rover\\
			&Then: See what rover number\\
			&\\	
			&Given: Rover UI of a rover\\
			&Then: See rover IP and port\\
			\hline
			\textbf{Remarks} &When I go to a dummy UI which has obviously no camera feed, then I get this ugly 404 error.\\
			\hline
		\end{tabularx}
		\caption{Acceptance test 2}
		\label{table:Acceptance test 2}   
	\end{table}
	\subsection{Use-case testing}
		\begin{table}[H]
		\centering
		\begin{tabularx}{\linewidth}{|X|X|}
			\hline
			\textbf{Use-case id} &1\\
			\hline
			\textbf{Use-case name} &Tracking the location of the rover.\\
			\hline
			\textbf{Primary actor} &Rover operator\\
			\hline
			\textbf{Secondary actor} &Rover\\
			\hline
			\textbf{Pre-conditions} &\begin{itemize}
										\item Rover operator has established a connection between the web interface and the rover.
										\item Rover operator has controller.
									\end{itemize}\\
			\hline
			\textbf{Success guarantee} &Rover operator tracks the location of the rover through a map on the web interface\\
			\hline
			\textbf{Main success scenario} &\begin{itemize}
												\item Rover operator uses controller to drive either forward, backward, left, or right.
												\item Rover operator sees location of the rover changing in the same direction as he/she is moving it.
											\end{itemize}\\
			\hline
			\textbf{Exceptions} &-\\
			\hline
			\textbf{Special requirements} &When the rover is unable to move in a certain direction because of an obstacle then this should be reflected in the map as not having moved.\\
			\hline
		\end{tabularx}
		\caption{Use-case test 1}
		\label{table:Use-case test 1}   
	\end{table}
	\begin{table}[H]
		\centering
		\begin{tabularx}{\linewidth}{|X|X|}
			\hline
			\textbf{Use-case id} &2\\
			\hline
			\textbf{Use-case name} &Backtracking the rover.\\
			\hline
			\textbf{Primary actor} &Rover operator\\
			\hline
			\textbf{Secondary actor} &Rover\\
			\hline
			\textbf{Pre-conditions} &\begin{itemize}
				\item Rover operator has established a connection between the web interface and the rover.
				\item Rover operator has controller
			\end{itemize}\\
			\hline
			\textbf{Success guarantee} &Rover returns to initial position in the opposite way as it has moved to its current position.\\
			\hline
			\textbf{Main success scenario} &\begin{itemize}
				\item Rover operator uses controller to drive either forward, backward, left, or right.
				\item Rover operator turns backtracking on.
				\item Rover goes back to its initial position.
			\end{itemize}\\
			\hline
			\textbf{Exceptions} &-\\
			\hline
			\textbf{Special requirements} &Moments where the rover stopped are ignored. So, the rover drives back directly without stopping.\\
			\hline
		\end{tabularx}
		\caption{Use-case test 2}
		\label{table:Use-case test 2}   
	\end{table}
	\begin{table}[H]
	\centering
	\begin{tabularx}{\linewidth}{|X|X|}
		\hline
		\textbf{Use-case id} &3\\
		\hline
		\textbf{Use-case name} &See data about rover\\
		\hline
		\textbf{Primary actor} &Rover operator\\
		\hline
		\textbf{Secondary actor} &Rover\\
		\hline
		\textbf{Pre-conditions} &\begin{itemize}
			\item Rover operator is on the control page/view.
		\end{itemize}\\
		\hline
		\textbf{Success guarantee} &Rover operator can read the following in the interface:
		\begin{itemize}
			\item Temperature at rover
			\item Camera shown at rover
			\item Position of servo of rover
			\item Distance between rover and object in front of it
			\item IP of rover
			\item Port at which  the operator is connected to
			\item Rover number	
		\end{itemize}
		\\
		\hline
		\textbf{Main success scenario} &\begin{enumerate}
			\item Rover operator reads temperature of from interface.
			\item Rover operator reads what camera of rover he/she sees in the interface.
			\item Rover operator reads position of servo.
			\item Rover operator reads IP of rover.
			\item Rover operator reads what port he/she is connected to.
			\item Rover operator reads which rover this is.	
		\end{enumerate}\\
		\hline
		\textbf{Exceptions} &-\\
		\hline
		\textbf{Special requirements} &-\\
		\hline
		\end{tabularx}
		\caption{Use-case test 3}
		\label{table:Use-case test 3}   
	\end{table}
 	\section{Design model}
 	As with the analysis of our product the design model contains multiple elements. These elements are as follows:
 	\begin{itemize}
 		\item Class diagram
 		\item Sequence diagram
 		\item Communication diagram
 		\item Hardware architecture
 	\end{itemize}
 	The design model answers the question of "how, in detail, is the product built?"
 	\subsection{Class diagram}
 		\begin{figure}[H]
 		\centering
 		\includegraphics[width=\linewidth]{MobileClassDiagram.png}\\
 		\caption{Class diagram for the mobile application}
 		\end{figure}
	 	\begin{figure}[H]
	 		\centering
	 		\includegraphics[width=\linewidth]{MainClassDiagram.png}\\
	 		\caption{Class diagram for the rover}
	 	\end{figure}
 	\subsection{Sequence diagram}
 	\begin{figure}[H]
 		\includegraphics[width=\linewidth]{SequenceDiagram1.png}
 		\caption{Sequence diagram for displaying text to the LCD screen}
 	\end{figure}
 	\subsection{Communication diagram}
 	\begin{figure}[H]
 		\centering
 		\includegraphics[width=\linewidth]{ComDiagram.png}\\
 		\caption{Description of the communication of our product}
 	\end{figure}
 	\subsection{Hardware architecture}
 	\begin{figure}[H]
 		\centering
 		\includegraphics[width=\linewidth]{HardwareArch.jpeg}\\
 		\caption{Diagram of our product's architecture}
 	\end{figure}
	\newpage
 	\section{Installation manual}
 	This manual contains the steps necessary for installing and configuring SR1(The rover). Upon completion the rover must be able to pass through all use-case test.\\
 	\subsubsection{Prerequisites}
 	In this document we assume the following are present:\\
 	\begin{itemize}
 		\item \textbf{SR1}
	 	\begin{itemize}
	 		\item \textbf{Controller}
	 		\begin{itemize}
	 			\item Raspberry Pi 3 Model B
	 			\begin{itemize}
	 				\item \emph{Onboard Wifi}
	 				\item \emph{Onboard BLE}
	 			\end{itemize}
	 			\item SD card (min. 16 GB)
	 			\item Rasbian Stretch installed on SD card
	 		\end{itemize}
	 		\item \textbf{Sensors and actuators}
	 		\begin{itemize}
	 			\item I2C PWM Controller BV6404[Byvac]
	 			\item Wheel encoder HC-020K
	 			\item Ultrasonic distance sensor SRF02
	 			\item Raspberry Pi 5MP camera with 6mm and 12mm lens
	 			\item HMC5883L GY-273 Triple Axis magnetometer[Honeywell]
	 			\item Servo motor MG90S
	 		\end{itemize}
	 		\item \textbf{Miscellaneous}
	 		\begin{itemize}
	 			\item Step down DC / DC converter 8V - 40V -> 5V
	 		\end{itemize}
	 	\end{itemize}
 	\end{itemize}
 	\subsection{Installation}
 	\emph{CD}\\
 	\emph{git clone \url{https://gitlab.fdmci.hva.nl/hadiyem/row}}\\
 	\\The following will be installed:
 	\begin{itemize}
 		\item \href{https://github.com/billz/raspap-webgui}{RaspAP}
 		\item \href{https://opencv.org/}{OpenCV}
 		\item \href{https://github.com/jacksonliam/mjpg-streamer}{Mjpg-streamer}
 		\item \href{http://flask.pocoo.org/}{Flask}
 		\item \href{https://github.com/miguelgrinberg/python-socketio}{Socket.IO (Python)}
 	\end{itemize}
	\subsubsection{Hotspot}
	Sources:
	\begin{itemize}
		\item \href{https://howtoraspberrypi.com/create-a-wi-fi-hotspot-in-less-than-10-minutes-with-pi-raspberry}{\emph{\underline{How to set up a hotspot}}}
	\end{itemize}
	\begin{lstlisting}
	sudo cp /etc/wpa_supplicant/wpa_supplicant.conf
	/etc/wpa_supplicant/wpa_supplicant.conf.sav
	sudo cp /dev/null/etc/wpa_supplicant/wpa_supplicant.conf
	ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev
	update_config=1
	
	wget -q https://git.io/voEUQ -O /tmp/raspap && bash /tmp/raspap
	\end{lstlisting}
	Notes:
	\begin{itemize}
		\item Use WinSCP to transfer files if the repo cannot be cloned due to access issues.
	\end{itemize}
	\subsubsection{Flask / Socket.IO (Python)}
	\begin{lstlisting}
		pip3 install gevent
		pip3 install Flask
		pip3 install flask-socketio
	\end{lstlisting}
	\subsubsection{OpenCV / Mjpg-streamer}
	Sources:
	\begin{itemize}
		\item \href{https://github.com/cncjs/cncjs/wiki/Setup-Guide:-Raspberry-Pi-\%7C-MJPEG-Streamer-Install-&-Setup-&-FFMpeg-Recording}{\emph{\underline{Mjpg-streamer}}}
		\item \href{https://www.pyimagesearch.com/2017/09/04/raspbian-stretch-install-opencv-3-python-on-your-raspberry-pi/}{\emph{\underline{OpenCV}}}
	\end{itemize}
	Enable camera and ssh in raspi-config
	\begin{lstlisting}
	
	sudo modprobe bcm2835-v4l2
	
	sudo apt-get update && sudo apt-get upgrade
	sudo apt-get install build-essential cmake pkg-config
	sudo apt-get install libjpeg-dev libtiff5-dev 
		libjasper-dev libpng12-dev -y
	sudo apt-get install libavcodec-dev libavformat-dev 
		libswscale-dev libv4l-dev -y
	sudo apt-get install libxvidcore-dev libx264-dev
	sudo apt-get install libgtk2.0-dev libgtk-3-dev
	sudo apt-get install libatlas-base-dev gfortran
	sudo apt-get install python2.7-dev python3-dev
	cd ~
	wget -O opencv.zip 
		https://github.com/Itseez/opencv/archive/3.3.0.zip
	unzip opencv.zip
	wget -O opencv_contrib.zip 
		https://github.com/Itseez/opencv_contrib/archive/3.3.0.zip
	unzip opencv_contrib.zip
	wget https://bootstrap.pypa.io/get-pip.py
	sudo python get-pip.py
	sudo python3 get-pip.py
	sudo pip install virtualenv virtualenvwrapper
	sudo rm -rf ~/.cache/pip
	
	echo -e "\n# virtualenv and virtualenvwrapper" 
		>> ~/.profile
	echo "export WORKON_HOME=$HOME/.virtualenvs" 
		>> ~/.profile
	echo "export VIRTUALENVWRAPPER_PYTHON=/usr/bin/python3" 
		>> ~/.profile
	echo "source /usr/local/bin/virtualenvwrapper.sh" 
		>> ~/.profile
	source ~/.profile
	
	mkvirtualenv cv -p python3
	source ~/.profile
	workon cv
	
	pip install numpy
	
	workon cv
	cd ~/opencv-3.3.0/
	mkdir build
	cd build
	cmake -D CMAKE_BUILD_TYPE=RELEASE \
	-D CMAKE_INSTALL_PREFIX=/usr/local \
	-D INSTALL_PYTHON_EXAMPLES=ON \
	-D OPENCV_EXTRA_MODULES_PATH=~/opencv_contrib-3.3.0/modules \
	-D BUILD_EXAMPLES=ON ..
	
	sudo nano /etc/dphys-swapfile
	set CONF_SWAPSIZE=1024
	
	sudo /etc/init.d/dphys-swapfile stop
	sudo /etc/init.d/dphys-swapfile start
	
	make -j4
	
	sudo make install
	sudo ldconfig
	
	cd /usr/local/lib/python3.5/site-packages/
	sudo mv cv2.cpython-35m-arm-linux-gnueabihf.so cv2.so
	
	cd ~/.virtualenvs/cv/lib/python3.5/site-packages/
	ln -s /usr/local/lib/python3.5/site-packages/cv2.so cv2.so
	
	cd
	rm -rf opencv-3.3.0 opencv_contrib-3.3.0
	
	sudo nano /etc/dphys-swapfile
	set CONF_SWAPSIZE=100
	
	sudo /etc/init.d/dphys-swapfile stop
	sudo /etc/init.d/dphys-swapfile start
	
	pip3 install Pillow
	pip3 install werkzeug
	
	sudo modprobe bcm2835-v4l2

	\end{lstlisting}
	\subsection{Configure startup}
	\begin{lstlisting}
	sudo nano /etc/rc.local
	\end{lstlisting}
	Add the following:
	\begin{lstlisting}
	# turns modules for driving, light, temperature, magnetometer, and 
		LCD on.
	sudo python3 /home/pi/row/main/main.py &
	
	# turns face recognition on
	sudo modprobe bcm2835-v4l2
	workon cv
	python2.7 /home/pi/row/fr/phase_3.py &
	source ~/.profile
	\end{lstlisting}
	\subsection{Configure addresses and ports}
	\begin{lstlisting}
	cd
	sudo nano RescueOnTheWheelsProject/constant.py
	Change the following in the script:
	CAM_PORT = 880<rovernummer>
	WEB_PORT = 990<rovernummer>
	\end{lstlisting}
	\subsection{Configure face recognition}
	\begin{lstlisting}
	cd
	mkdir dataset
	mkdir Cascades
	cd Cascades
	wget https://github.com/opencv/opencv/blob/master/data/
		haarcascades/haarcascade_frontalface_default.xml
	cd
	mkdir trainer
	\end{lstlisting}
	\subsection{Configure Wifi hotspot}
	\begin{enumerate}
		\item Connect through Wifi to raspi-webgui.
		\item Open your browser and go to: 10.3.141.1.
		\item Type in username and password:
		\begin{itemize}
			\item Username: admin
			\item Password: secret
		\end{itemize}
		\item Go to Configure hotspot.
		\item Change the SSID from raspi-webgui to Rover 0<number of rover>.
		\item Save settings and restart the rover.
	\end{enumerate}
	\begin{figure}[H]
		\includegraphics[width=\columnwidth]{InstallManual.png}
	\end{figure}
	\newpage
 	\section{User manual}
 	This manual explains how to sue the rover in detail. This section assumes you have the latest version of the rover and its software properly installed, according to the installation manual, and that the rover is turned on. It also assumes basic computer skills required for the job of operating this product. As for the mobile version, it also assumes you have the latest version installed.
 	\subsection{Web application}
 	Our web application is reachable by any browser but to ensure compatibility with all implemented features in the web application it is recommended to use the latest version of Mozilla Firefox.\\
 	To reach the app you first have to connect to the wifi hot-spot called "Rover 08". We assigned a static ip address for the usage of the application: 10.3.141.1 with corresponding port: 8080.
 	\begin{figure}[H]
 		\includegraphics[width=\columnwidth]{Webpage.png}
 		\caption{The web application}
 	\end{figure} 
 	When you enter the web application you will encounter a lit of all rovers that are currently in service. You have to select rover 08 as the others are currently placeholders and will be developed at a later time when there is a desire to do so. After you select rover 08 you click connect which forwards you to the interface of our web app as seen in the image above. On the left you have the option to select a special face recognition feature as well as the dashboard, which is the currently selected one in the image aforementioned. Furthermore, the dashboard contains the live camera-feed as well as the tracking map of the rover's movement and a variety of measurements displayed in a clear and concise manner.\\
 	Next, you'll find a brief description of the four most important features of our web application.
 	\subsubsection{Camera-feed}
 	The camera feed automatically opens when you reach the interface. It shows what the rover sees but also has the added functionality of "recognizing" faces. When the system detects a face it puts a square around to face to indicate that a human face has been detected. It shows this as a percentage in comparison to the face that the rover has been trained with.
 	\subsubsection{Rover control}
 	The rover can be controlled using the \textbf{WASD} keys on the keyboard of the device in question. Make sure the focus of the system is the webpage otherwise the key input will not result in movement. Based on the movement of the rover a line will be generated in the box on the right of the camera-feed. This line is a "best effort" representation of the movement performed by the rover.
 	\subsubsection{Text prompt}
 	At the bottom of the interface there is a text input field where the operator can send a small text message to the LCD screen on the rover. The rover then displays this text to whoever the rover is close to.
 	\subsubsection{Microphone}
 	Next to the text prompt field is a button to enable the device's microphone. After allowing the device to access said microphone you can speak into the microphone and it will be broadcast through a speaker on the rover.
 	\subsection{Mobile application}
 	The mobile application is a slim, light weight version of the our web application. Designed to be used in circumstances where the web interface is not the best solution to the problem.
 	The web application has a few less features but has the addition of a virtual joystick for better control of the rover's movement. Below you'll find the mobile application's interface.
 	\begin{figure}[H]
 		\includegraphics[width=\columnwidth]{MobileApp.jpg}
 	\end{figure}
\end{document}	